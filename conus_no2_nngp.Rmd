---
title: "Simple NNGP"
author: "Elizabeth Chun"
date: "2024-11-11"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
# library(FRK)

# load packages
library(tidyverse)
library(tictoc)

library(geoR)
library(BRISC)

# plotting
library(sf)
library(basemapR)
```


# load data

Choose median NO2 as response and filter to only Daily Maximum 1-hour average values.

```{r}
annual_conc_by_monitor_2019 <- read_csv("final_project/data/annual_conc_by_monitor_2019.csv")

no2 = annual_conc_by_monitor_2019 %>% filter(`Parameter Name` == 'Nitrogen dioxide (NO2)') 

no2_filt = no2 %>%
  filter(`Metric Used` == 'Daily Maximum 1-hour average') %>%
  filter(!(`State Code` %in% c('02', '15', '72'))) %>% # remove alaska, hawaii, puerto rico
  select(lon = Longitude, lat = Latitude, no2_ppb = '50th Percentile')
```

```{r}
no2_filt_sf = st_as_sf(no2_filt, coords = c('lon', 'lat'), crs = 4326)
bbox_no2 = st_bbox(no2_filt_sf)

no2_filt_sf %>%
  ggplot() + 
    base_map(bbox_no2, increase_zoom = 4, basemap = 'mapnik') +
    geom_sf(aes(color = no2_ppb), alpha = 0.75, size = 2) +
    scale_color_gradient2(low = 'darkgreen', mid = 'orange', high = "red", 
                         limits = c(0, 45), na.value = NA, midpoint = 22)
```


# NNGP without covariates

## Split data

```{r data splitting}
### data splitting
set.seed(1)

# get 80/20 train test split
train_idx = sample(nrow(no2_filt), 0.8*nrow(no2_filt))
train_all = no2_filt[train_idx, ]
test_all = no2_filt[-train_idx, ]
```

```{r}
st_as_sf(train_all, coords = c('lon', 'lat'), crs = 4326) %>%
  ggplot() + 
    base_map(bbox_no2, increase_zoom = 1, basemap = 'mapnik') +
    geom_sf(aes(color = no2_ppb), alpha = 0.75, size = 2) +
    scale_color_gradient2(low = 'darkgreen', mid = 'orange', high = "red", 
                         limits = c(0, 45), na.value = NA, midpoint = 22)
```

```{r}
st_as_sf(test_all, coords = c('lon', 'lat'), crs = 4326) %>%
  ggplot() + 
    base_map(bbox_no2, increase_zoom = 1, basemap = 'mapnik') +
    geom_sf(aes(color = no2_ppb), alpha = 0.75, size = 2) +
    scale_color_gradient2(low = 'darkgreen', mid = 'orange', high = "red", 
                         limits = c(0, 45), na.value = NA, midpoint = 22)
```

## model fitting

NO2 response, lat lon as covariates and spatial coords.

```{r fit nngp}
fit_nngp = BRISC_estimation(coords = as.matrix(train_all[, c('lon', 'lat')]), 
                            x = cbind(1, as.matrix(train_all[, c("lon", 'lat')])), 
                            y = train_all$no2_ppb, 
                            cov.model = 'exponential', n.neighbors = 10)
print(fit_nngp$Beta)
print(fit_nngp$Theta)
```



### prediction results

Predict for both train and test sets - see overfitting.

```{r}
preds_nngp = BRISC_prediction(fit_nngp, coords.0 = as.matrix(train_all[, c('lon', 'lat')]), 
                              X.0 = cbind(1, as.matrix(train_all[, c('lon', 'lat')])))
rmse_nngp = sqrt(mean((train_all$no2_ppb - preds_nngp$prediction)^2))
smape = mean(abs(preds_nngp$prediction - train_all$no2_ppb)/
              ((abs(train_all$no2_ppb) + abs(preds_nngp$prediction))/2)) * 100

resids = train_all$no2_ppb - preds_nngp$prediction

print(rmse_nngp)
print(smape)

hist(resids)
hist(preds_nngp$prediction)
```

```{r nngp prediction}
preds_nngp = BRISC_prediction(fit_nngp, coords.0 = as.matrix(test_all[, c('lon', 'lat')]), 
                              X.0 = cbind(1, as.matrix(test_all[, c('lon', 'lat')])))
rmse_nngp = sqrt(mean((test_all$no2_ppb - preds_nngp$prediction)^2))
smape = mean(abs(preds_nngp$prediction - test_all$no2_ppb)/
              ((abs(test_all$no2_ppb) + abs(preds_nngp$prediction))/2)) * 100

resids = test_all$no2_ppb - preds_nngp$prediction

print(rmse_nngp)
print(smape)

hist(resids)
hist(preds_nngp$prediction)
```


```{r}
# plot random predictions map

pred_df_rand = test_all[, c('lon', 'lat')] %>%
  mutate(
    no2_ppb_pred = preds_nngp$prediction,
    resids = test_all$no2_ppb -  preds_nngp$prediction
  ) 
pred_df_rand_sf = st_as_sf(pred_df_rand, coords = c('lon', 'lat'), crs = 4326)

ggplot(pred_df_rand_sf) + 
  base_map(bbox_no2, increase_zoom = 1, basemap = 'mapnik') +
  geom_sf(aes(color = no2_ppb_pred), alpha = 0.75, size = 2) +
  scale_color_gradient2(low = 'darkgreen', mid = 'orange', high = "red", 
                       limits = c(0, 40), na.value = NA, midpoint = 20)
```

```{r}
ggplot(pred_df_rand_sf) + 
  base_map(bbox_no2, increase_zoom = 1, basemap = 'mapnik') +
  geom_sf(aes(color = resids), alpha = 0.75, size = 2) +
  scale_color_gradient2(low = 'darkyellow', mid = 'darkgreen', high = "red", 
                       limits = c(-16, 26), na.value = NA, midpoint = 0)
```

# NNGP with covariates

Read data with covariates - from Sophia

```{r}
no2_covar <- read_csv("final_project/data/NO2_CONUS_full_data.csv")
```
## data splitting

Set the same seed for splitting to ensure fairness.

```{r data splitting}
### data splitting
set.seed(1)

# get 80/20 train test split
train_idx = sample(nrow(no2_covar), 0.8*nrow(no2_covar))
train_all = no2_covar[train_idx, ]
test_all = no2_covar[-train_idx, ]
```

## model fitting

Include covariates in model

```{r fit nngp}
covars = c('Longitude', 'Latitude', 'total_population', 'total_no_vehicle',
           'total_carpool_vehicle',
           'total_private_vehicle', 'total_public_transit', 'ppt', 'tmax', 'tmin', 'tmean')
fit_nngp = BRISC_estimation(coords = as.matrix(train_all[, c('Longitude', 'Latitude')]), 
                            x = cbind(1, as.matrix(train_all[, covars])), 
                            y = train_all$X50th.Percentile, 
                            cov.model = 'exponential', n.neighbors = 10)
print(fit_nngp$Beta)
print(fit_nngp$Theta)
```



## prediction results with covariates

Again, train and test set prediction errors.


```{r}
preds_nngp = BRISC_prediction(fit_nngp, coords.0 = as.matrix(train_all[, c('Longitude', 'Latitude')]), 
                              X.0 = cbind(1, as.matrix(train_all[, covars])))
rmse_nngp = sqrt(mean((train_all$X50th.Percentile - preds_nngp$prediction)^2))
smape = mean(abs(preds_nngp$prediction - train_all$X50th.Percentile)/
              ((abs(train_all$X50th.Percentile) + abs(preds_nngp$prediction))/2)) * 100

resids = train_all$X50th.Percentile - preds_nngp$prediction

print(rmse_nngp)
print(smape)

hist(resids)
hist(preds_nngp$prediction)
```

```{r nngp prediction}
preds_nngp = BRISC_prediction(fit_nngp, coords.0 = as.matrix(test_all[, c('Longitude', 'Latitude')]), 
                              X.0 = cbind(1, as.matrix(test_all[, covars])))
rmse_nngp = sqrt(mean((test_all$X50th.Percentile - preds_nngp$prediction)^2))
smape = mean(abs(preds_nngp$prediction - test_all$X50th.Percentile)/
              ((abs(test_all$X50th.Percentile) + abs(preds_nngp$prediction))/2)) * 100

resids = test_all$X50th.Percentile - preds_nngp$prediction

print(rmse_nngp)
print(smape)

hist(resids)
hist(preds_nngp$prediction)
```


```{r}
# plot random predictions map

pred_df_rand = test_all[, c('lon', 'lat')] %>%
  mutate(
    no2_ppb_pred = preds_nngp$prediction,
    resids = test_all$no2_ppb -  preds_nngp$prediction
  ) 
pred_df_rand_sf = st_as_sf(pred_df_rand, coords = c('lon', 'lat'), crs = 4326)

ggplot(pred_df_rand_sf) + 
  base_map(bbox_no2, increase_zoom = 1, basemap = 'mapnik') +
  geom_sf(aes(color = no2_ppb_pred), alpha = 0.75, size = 2) +
  scale_color_gradient2(low = 'darkgreen', mid = 'orange', high = "red", 
                       limits = c(0, 40), na.value = NA, midpoint = 20)
```

```{r}
ggplot(pred_df_rand_sf) + 
  base_map(bbox_no2, increase_zoom = 1, basemap = 'mapnik') +
  geom_sf(aes(color = resids), alpha = 0.75, size = 2) +
  scale_color_gradient2(low = 'darkyellow', mid = 'darkgreen', high = "red", 
                       limits = c(-16, 26), na.value = NA, midpoint = 0)
```




# predict on rough grid - legacy code

```{r}
si <- expand.grid(lon =seq(from = -106, to = -93, by = 0.5), 
                  lat = seq(from = 25, to = 36, by = 0.5))
si_sf = st_as_sf(si, coords = c('lon', 'lat'), crs = 4326)

tx_xform = sf::st_transform(tx, crs = 4326)
texas_si = si_sf[tx_xform, ]

texas_si_final = texas_si %>% 
  st_drop_geometry() %>%  
  bind_cols(st_coordinates(texas_si)) %>%
  select(lat = Y, lon = X)
```


```{r nngp prediction}
preds_grid = BRISC_prediction(fit_nngp, coords.0 = as.matrix(texas_si_final), 
                              X.0 = cbind(1, as.matrix(texas_si_final)))

hist(preds_grid$prediction)
```

```{r}
# plot random predictions map

pred_df_rand = texas_si_final %>%
  mutate(
    no2_ppm_pred = preds_grid$prediction
  ) 
pred_df_rand_sf = st_as_sf(pred_df_rand, coords = c('lon', 'lat'), crs = 4326)

ggplot(pred_df_rand_sf) + 
  base_map(bbox_no2, increase_zoom = 1, basemap = 'mapnik') +
  geom_sf(aes(color = no2_ppm_pred), alpha = 1, size = 3) +
  scale_color_gradient2(low = 'darkgreen', mid = 'orange', high = "red", 
                       limits = c(0, 26), na.value = NA, midpoint = 20)
```


