---
title: "Simple NNGP"
author: "Elizabeth Chun"
date: "2024-11-11"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
# library(FRK)

# load packages
library(tidyverse)
library(tictoc)

library(geoR)
library(BRISC)

# plotting
library(sf)
```


# load data

```{r}
annual_conc_by_monitor_2019 <- read_csv("final_project/annual_conc_by_monitor_2019.csv")

no2 = annual_conc_by_monitor_2019 %>% filter(`Parameter Name` == 'Nitrogen dioxide (NO2)') 

no2_filt = no2 %>%
  filter(`Metric Used` == 'Daily Maximum 1-hour average') %>%
  filter(!(`State Code` %in% c('02', '15', '72'))) %>% # remove alaska, hawaii, puerto rico
  select(lon = Longitude, lat = Latitude, no2_ppb = '50th Percentile')
```

```{r}
no2_filt_sf = st_as_sf(no2_filt, coords = c('lon', 'lat'), crs = 4326)
bbox_no2 = st_bbox(no2_filt_sf)

no2_filt_sf %>%
  ggplot() + 
    base_map(bbox_no2, increase_zoom = 4, basemap = 'mapnik') +
    geom_sf(aes(color = no2_ppb), alpha = 0.75, size = 2) +
    scale_color_gradient2(low = 'darkgreen', mid = 'orange', high = "red", 
                         limits = c(0, 45), na.value = NA, midpoint = 22)
```


# NNGP

```{r data splitting}
### data splitting
set.seed(1)

# get 80/20 train test split
train_idx = sample(nrow(no2_filt), 0.8*nrow(no2_filt))
train_all = no2_filt[train_idx, ]
test_all = no2_filt[-train_idx, ]
```

```{r}
st_as_sf(train_all, coords = c('lon', 'lat'), crs = 4326) %>%
  ggplot() + 
    base_map(bbox_no2, increase_zoom = 1, basemap = 'mapnik') +
    geom_sf(aes(color = no2_ppb), alpha = 0.75, size = 2) +
    scale_color_gradient2(low = 'darkgreen', mid = 'orange', high = "red", 
                         limits = c(0, 45), na.value = NA, midpoint = 22)
```

```{r}
st_as_sf(test_all, coords = c('lon', 'lat'), crs = 4326) %>%
  ggplot() + 
    base_map(bbox_no2, increase_zoom = 1, basemap = 'mapnik') +
    geom_sf(aes(color = no2_ppb), alpha = 0.75, size = 2) +
    scale_color_gradient2(low = 'darkgreen', mid = 'orange', high = "red", 
                         limits = c(0, 45), na.value = NA, midpoint = 22)
```


## 3.2 Nearest neighbors GP

Now I will fit an NNGP on the entire training set with 10 neighbors using the BRISC package.

```{r fit nngp}
fit_nngp = BRISC_estimation(coords = as.matrix(train_all[, c('lon', 'lat')]), 
                            x = cbind(1, as.matrix(train_all[, c("lon", 'lat')])), 
                            y = train_all$no2_ppb, 
                            cov.model = 'exponential', n.neighbors = 10)
print(fit_nngp$Beta)
print(fit_nngp$Theta)
```



# 4. Model results and predictions

## 4.2 Nearest neighbors GP

For the NNGP, here are the estimated parameters. Note that BRISC reports $\phi$ as the reciprocal of the standard definition so I have taken $\frac{1}{\phi}$.

$\hat{\beta}$'s = [`r fit_nngp$Beta`]  
$\hat{\sigma}^2$ = `r fit_nngp$Theta[1]`  
$\phi$ = `r 1/fit_nngp$Theta[3]`  
$\hat{\tau}^2$ = `r fit_nngp$Theta[2]`    


```{r}
preds_nngp = BRISC_prediction(fit_nngp, coords.0 = as.matrix(train_all[, c('lon', 'lat')]), 
                              X.0 = cbind(1, as.matrix(train_all[, c('lon', 'lat')])))
rmse_nngp = sqrt(mean((train_all$no2_ppb - preds_nngp$prediction)^2))
smape = mean(abs(preds_nngp$prediction - train_all$no2_ppb)/
              ((abs(train_all$no2_ppb) + abs(preds_nngp$prediction))/2)) * 100

resids = train_all$no2_ppb - preds_nngp$prediction

print(rmse_nngp)
print(smape)

hist(resids)
hist(preds_nngp$prediction)
```

```{r nngp prediction}
preds_nngp = BRISC_prediction(fit_nngp, coords.0 = as.matrix(test_all[, c('lon', 'lat')]), 
                              X.0 = cbind(1, as.matrix(test_all[, c('lon', 'lat')])))
rmse_nngp = sqrt(mean((test_all$no2_ppb - preds_nngp$prediction)^2))
smape = mean(abs(preds_nngp$prediction - test_all$no2_ppb)/
              ((abs(test_all$no2_ppb) + abs(preds_nngp$prediction))/2)) * 100

resids = test_all$no2_ppb - preds_nngp$prediction

print(rmse_nngp)
print(smape)

hist(resids)
hist(preds_nngp$prediction)
```


```{r}
# plot random predictions map

pred_df_rand = test_all[, c('lon', 'lat')] %>%
  mutate(
    no2_ppb_pred = preds_nngp$prediction,
    resids = test_all$no2_ppb -  preds_nngp$prediction
  ) 
pred_df_rand_sf = st_as_sf(pred_df_rand, coords = c('lon', 'lat'), crs = 4326)

ggplot(pred_df_rand_sf) + 
  base_map(bbox_no2, increase_zoom = 1, basemap = 'mapnik') +
  geom_sf(aes(color = no2_ppb_pred), alpha = 0.75, size = 2) +
  scale_color_gradient2(low = 'darkgreen', mid = 'orange', high = "red", 
                       limits = c(0, 40), na.value = NA, midpoint = 20)
```

```{r}
ggplot(pred_df_rand_sf) + 
  base_map(bbox_no2, increase_zoom = 1, basemap = 'mapnik') +
  geom_sf(aes(color = resids), alpha = 0.75, size = 2) +
  scale_color_gradient2(low = 'darkyellow', mid = 'darkgreen', high = "red", 
                       limits = c(-16, 26), na.value = NA, midpoint = 0)
```


# predict on rough grid

```{r}
si <- expand.grid(lon =seq(from = -106, to = -93, by = 0.5), 
                  lat = seq(from = 25, to = 36, by = 0.5))
si_sf = st_as_sf(si, coords = c('lon', 'lat'), crs = 4326)

tx_xform = sf::st_transform(tx, crs = 4326)
texas_si = si_sf[tx_xform, ]

texas_si_final = texas_si %>% 
  st_drop_geometry() %>%  
  bind_cols(st_coordinates(texas_si)) %>%
  select(lat = Y, lon = X)
```


```{r nngp prediction}
preds_grid = BRISC_prediction(fit_nngp, coords.0 = as.matrix(texas_si_final), 
                              X.0 = cbind(1, as.matrix(texas_si_final)))

hist(preds_grid$prediction)
```

```{r}
# plot random predictions map

pred_df_rand = texas_si_final %>%
  mutate(
    no2_ppm_pred = preds_grid$prediction
  ) 
pred_df_rand_sf = st_as_sf(pred_df_rand, coords = c('lon', 'lat'), crs = 4326)

ggplot(pred_df_rand_sf) + 
  base_map(bbox_no2, increase_zoom = 1, basemap = 'mapnik') +
  geom_sf(aes(color = no2_ppm_pred), alpha = 1, size = 3) +
  scale_color_gradient2(low = 'darkgreen', mid = 'orange', high = "red", 
                       limits = c(0, 26), na.value = NA, midpoint = 20)
```

